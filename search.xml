<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[HIve-入门]]></title>
    <url>%2F2019%2F02%2F19%2FHIve-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1.目标基本上，对于查询和分析存储在Hadoop文件中的大型数据集，我们使用Apache Hive。但是，还有更多的Hive概念，我们将在这个Apache Hive教程中讨论，您可以了解什么是Apache Hive。因此，在这个Apache Hive教程中，我们将学习Hive历史。此外，我们将看到为什么使用Hive - 学习Hive的原因。此外，我们将介绍Hive架构或组件以便更好地理解。之后，我们还将介绍其局限性，Hive如何工作，Hive vs SparkSQL以及Pig vs Hive vs Hadoop MapReduce。 那么，让我们开始Hive教程。 2.什么是Apache Hive？Apache Hive是一个基于Hadoop Haused构建的开源数据仓库系统。特别是，我们使用它来查询和分析存储在Hadoop文件中的大型数据集。此外，通过使用Hive，我们可以在Hadoop中处理结构化和半结构化数据 。 换句话说，它是一个数据仓库基础设施，便于查询和管理驻留在分布式存储系统中的大型数据集。基本上，它提供了一种使用类似SQL的查询语言HiveQL（Hive Query Language）查询数据的方法。 此外，编译器在内部将HiveQL语句转换为MapReduce作业。进一步提交给Hadoop框架执行。 一个。蜂巢不是 有时，Hive几乎没有误解。那么，让我们澄清一下： 我们可以说它不是关系数据库此外，不是OnLine事务处理（OLTP）的设计甚至不是用于实时查询和行级更新的语言了解如何在Ubuntu上安装Apache Hive - 逐步详细说明。 获得IT行业最苛刻的技能 - 学习HadoopEmailPhone with country code3.为何选择Hi​​ve？在Hive教程的这一部分中，我们讨论 - 为什么要使用Apache Hive技术？ 我们知道它主要用于数据查询，分析和汇总。此外，它有助于提高开发人员的工作效率。然而，这是以增加延迟和降低效率为代价的。换句话说，Hive是SQL的变体，确实非常好。虽然与数据库中实现的SQL系统相比，Hive仍然很高。Hive有许多用户定义的函数，可以很容易地为UDF做出贡献。此外，我们可以将Hive查询连接到各种Hadoop包。比如RHive，RHipe，甚至Apache Mahout。但是，在处理具有挑战性的复杂分析处理和数据格式时，它对开发人员社区有很大帮助。 更具体地说，“数据仓库”是指我们用于报告和数据分析的系统。基本上，它指的是检查，清理，转换和建模数据，目的是发现有用的信息并提出结论。此外，在不同的商业，科学和社会科学领域，数据分析具有多个方面和方法，包括各种名称下的各种技术。 此外，它允许用户同时访问数据并增加响应时间。它表示系统或功能单元对给定输入作出反应所花费的时间。此外，它在相同类型的巨大数据集上的响应时间比大多数其他类型的查询快得多。此外，在不降低性能的情况下，它非常灵活，因为可以轻松添加更多商品以响应更多数据集的添加。 我们将详细讨论Hive分区，Hive分区类型与示例。 Hive教程 - 历史基本上，在Facebook，数据基础架构团队开发了Hive。特别是，为了满足Facebook的要求，他们使用Hive技术。在内部，它非常受Facebook上所有用户的欢迎。具体而言，对于各种各样的应用程序，它被用于在数百个用户的集群上运行数千个作业。此外，Hive-Hadoop集群在Facebook上存储了超过2PB的原始数据。此外，它每天定期加载15 TB的数据。 此外，非常重要的是要知道它正在被许多公司使用和开发。如亚马逊，IBM，雅虎，Netflix，金融业监管局（FINRA）等。让我们详细讨论Hive Partitioning与Bucketing之间 的 重要区别。 Hive Architecture在下面的图中，Hive教程描述了Hive架构及其组件： Apache HiveHive教程 - Hive架构 该组件图中有几个不同的单元。现在，我们来描述每个单元： 一个。用户界面 我们知道它是一个数据仓库基础架构软件。它可以在用户和HDFS之间创建交互。此外，Hive支持各种用户界面。它们是Hive Web UI，Hive命令行和Hive HD Insight（在Windows服务器中）。 湾 Meta Store 基本上，为了存储表，数据库，表中的列，它们的数据类型和HDFS映射的模式或元数据，它选择相应的数据库服务器。 详细了解Hive MetaStore，请点击链接：Hive - Metastore C。HiveQL流程引擎 另外，我们可以说HiveQL与SQL相同。特别是，用于查询Metastore上的架构信息。此外，对于MapReduce程序，它是传统方法的替代品之一。此外，我们可以编写MapReduce作业的查询并处理它，而不是用Java编写MapReduce程序。 d。执行引擎 虽然，Hive Execution Engine是HiveQL流程Engine和MapReduce的结合部分。执行引擎处理查询并生成与MapReduce结果相同的结果。此外，它使用MapReduce的味道。 即 HDFS或HBase 基本上，将数据存储到文件系统Hadoop分布式文件系统或HBase是数据存储技术。 请点击此链接，了解更多关于蜂巢结构及零部件 详细 Hive如何工作？Hive教程 - 下图描绘了Hive和Hadoop之间的工作流程。 Apache HiveApache Hive教程 - Hive的工作 下表定义了Hive如何与Hadoop框架交互。 步骤1执行查询 最初，Hive接口（命令行或Web UI）将查询发送到Driver（任何数据库驱动程序，如JDBC，ODBC等）以执行。 第2步获取计划 然后，驱动程序借助查询编译器来解析查询，以检查语法和查询计划或查询的要求。 第3步获取元数据 此外，编译器将元数据请求发送到Metastore（任何数据库）。 步骤4发送元数据 之后，Metastore将元数据作为对编译器的响应发送。 第5步发送计划 然后编译器检查需求并将计划重新发送到驱动程序。但是，查询的解析和编译已完成，直到此处。 步骤6执行计划 此外，驱动程序将执行计划发送到执行引擎。 步骤7执行作业 然后，执行作业的过程是内部的MapReduce作业。此外，执行引擎将作业发送到JobTracker，JobTracker位于名称节点中，并将此作业分配给位于数据节点中的TaskTracker。而且，查询在这里执行MapReduce作业。 元数据操作在执行期间，执行引擎可以使用Metastore执行元数据操作。 步骤8获取结果 执行结束时，执行引擎从Data节点接收结果。 第9步发送结果 获取结果后，执行引擎会将这些结果值发送给驱动程序。 第10步发送结果 最后，驱动程序将结果发送到Hive接口。 7.蜂巢的特点在Hive教程的这一部分中，我们研究了Apache Hive功能。那么，让我们讨论所有 - 最好的功能是以更简单的方式提供数据汇总，查询和分析。但是，为了在不实际存储在HDFS中的情况下处理数据，Hive支持外部表。而且，它完全符合Hadoop的低级接口要求。此外，为了提高性能，它支持在表级别对数据进行分区。在优化逻辑计划方面，Hive有一个基于规则的优化器。Hive本质上是可扩展的，熟悉的和可扩展的。对于使用HiveQL知识的基本SQL查询就足够了。我们不需要任何编程语言知识。通过使用Hive，可以在Hadoop中处理结构化数据。与SQL一样，Hive使查询变得非常简单。通过使用Hive，可以为数据分析运行Ad-hoc查询8.蜂巢的限制Apache Hive教程讨论了Hive的以下限制。我们来讨论所有 - 我们无法使用Hive执行实时查询。此外，它不提供行级更新。此外，对于交互式数据浏览，Hive提供可接受的延迟。另外，我们可以说Hive不是在线交易处理的正确选择。虽然涉及延迟，但对于Hive查询，延迟通常非常高。 学习如何在Hive中详细开发数据模型。 Apache Hive教程 - 用法在这里，我们将看看以下Hive用法。 我们使用Hive for Schema灵活性和进化。此外，Apache Hive中的分区和桶表也是可能的。此外，我们可以使用JDBC / ODBC驱动程序，因为它们在Hive中可用。 Hive vs Spark SQLApache Hive 在Apache Hive教程的这一部分中，我们将详细比较Hive与Spark SQL。一个。初始发行 Apache Hive蜂巢于2012年首次发布。 Spark SQL而Spark SQL于2014年首次发布.b。当前版本 Apache Hive目前于2017年11月18日发布：版本2.3.2 Spark SQL目前于2017年10月9日发布：版本2.1.2c。开发人员 Apache HiveFacebook最初开发了它。进一步捐赠给Apache软件基金会，从那以后一直保持着它。 Spark SQLApache Software Foundation最初开发了它。d。服务器操作系统 Apache Hive但是，对于Java VM，它支持所有操作系统。 Spark SQLSpark SQL支持许多操作系统。例如Linux OS，X和Windows。即 数据类型 Apache Hive它获得了预定义的数据类型。例如，浮动或日期。详细了解有关Hive数据类型的更多信息 Spark SQL与Spark SQL一样，它也可以获得预定义的数据类型。例如，浮点数或日期。F。支持SQL Apache Hive基本上，它拥有类似SQL的DML和DDL语句。 Spark SQL与Hive一样，它也拥有类似SQL的DML和DDL语句。学习完整的比较，点击链接，Apache Hive vs Spark SQL：功能明智的比较 Hadoop测验 Pig vs Hive vs Hadoop MapReduceApache HiveApache Hive教程 - Pig vs Hive vs Hadoop MapReduce 在Apache Hive教程的这一部分中，获得Pig vs Hive与Hadoop Mapreduce的完全区别。一个。语言 蜂巢它有像Query语言一样的SQL。 MapReduce的还有，编译语言。 猪它有脚本语言。湾 抽象化 蜂巢它具有低水平的抽象。 MapReduce的此外，具有高水平的抽象。 猪它具有高水平的抽象。C。代码行 蜂巢相对较少没有。MapReduce和Pig的代码行。 MapReduce的它有更多代码。 猪相对较少没有。来自MapReduce的代码行。d。发展努力 蜂巢MapReduce和Pig的开发工作相对较少。 MapReduce的涉及更多的开发工作。 猪相对较少的开发努力。即 代码效率 蜂巢代码效率相对较低。 MapReduce的它具有很高的代码效率。 猪代码效率相对较低。让我们详细修改Hive Operators。 所以，这一切都在Apache Hive教程中。希望你喜欢我们的解释。 12.结论 - Hive教程因此，在这个Apache Hive教程中，我们已经看到了Apache Hive的概念。它包括Hive架构，Hive的局限性，优势，Hive需要的原因，Hive History，Hive vs Spark SQL以及Pig vs Hive vs Hadoop MapReduce。但是，如果您不得不询问有关此Apache Hive教程的任何查询，请随时通过评论部分询问。另请参阅 - 最佳Apache Hive Books]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive-介绍]]></title>
    <url>%2F2019%2F02%2F19%2FHive-%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[本文章翻译来自Data-flair 1.目标Apache Hive是一个基于Hadoop Haused构建的开源数据仓库系统，用于查询和分析存储在Hadoop文件中的大型数据集。它在Hadoop中处理结构化和半结构化数据。这个Apache Hive教程详细介绍了Apache Hive和Hive历史的基础知识。在这个配置单元教程中，我们将了解Hive的需求及其特性。此Hive指南还介绍了Hive体系结构的内部结构、Hive功能和Apache Hive的缺点。那么，让我们开始Apache Hive教程。 2.什么是Hive?Apache Hive是一个基于Hadoop Haused构建的开源数据仓库系统，用于查询和分析存储在Hadoop文件中的大型数据集。最初，你必须编写复杂的 Map-Reduce作业，但现在在Hive的帮助下，你只需要提交SQL查询。Hive主要针对熟悉SQL的用户。Hive使用称为HiveQL（HQL）的语言，它类似于SQL。HiveQL自动将类似SQL的查询转换为MapReduce作业。Hive抽象了Hadoop的复杂性。需要注意的主要事情是没有必要为Hive学习java。Hive通常在您的工作站上运行，并将您的SQL查询转换为一系列作业，以便在Hadoop集群上执行。Apache Hive将数据组织到表中。这提供了一种将结构附加到存储在HDFS中的数据的方法。 3. Hive的历史Facebook数据基础架构团队开发了Hive。Apache Hive也是用于满足Facebook要求的技术之一。它非常受Facebook内部所有用户的欢迎。它被用于在具有数百个用户的群集上运行数千个作业，用于各种应用程序。Facebook上的Apache Hive-Hadoop集群存储了超过2PB的原始数据。它每天定期加载15TB的数据。现在它被亚马逊，IBM，雅虎，Netflix，金融业监管局（FINRA）等许多公司使用和开发。 4.为什么选择Hive?让我们现在讨论Hive的需求 -Facebook在实施Apache Hive之前遇到了很多挑战。生成的数据大小等挑战增加或爆炸，使得处理它们变得非常困难。传统的RDBMS无法应对压力。因此，Facebook正在寻找更好的选择。为了解决这个问题，Facebook最初尝试使用MapReduce。但它在SQL编程和强制知识方面存在困难，使其成为一种不切实际的解决方案。因此，Apache Hive允许他们克服他们所面临的挑战。使用Apache Hive，他们现在可以执行以下操作： 架构灵活性和演变 表可以分配和分段 Apache Hive表直接在HDFS中定义 JDBC/ODBC驱动程序可用 Apache Hive使开发人员无需编写复杂的Hadoop MapReduce作业即可满足临时需求。因此，hive提供数据的摘要，分析和查询。Hive非常快速且可扩展。它具有很强的可扩展性。由于Apache Hive与SQL类似，因此SQL开发人员很容易学习和实现Hive查询。Hive通过提供用户可以提交SQL查询的界面来降低MapReduce的复杂性。因此，现在业务分析师可以使用Apache Hive使用大数据并生成报表。它还提供各种数据存储（如 HDFS和HBase）的文件访问。Apache Hive最重要的特性是学习Hive，我们不必学习Java。 5. Hive 结构在介绍Apache Hive之后，现在我们将讨论Hive结构的主要组件。Apache Hive组件是 Metastore 它存储每个表的元数据，如模式和存储位置。Hive还包括分区元数据。这有助于Driver跟踪在群集上分布的各种数据集的进度。它以传统的RDBMS格式存储数据。Hive元数据可帮助Driver跟踪数据，这非常重要。备份服务器会定期复制在数据丢失时可以检索的数据。 Driver -它就像一个接收HiveQL语句的控制器。Driver通过创建会话来启动SQL语句的执行。它监视生命周期和执行进度。Driver存储在执行HiveQL语句期间生成的必要元数据。它还充当Reduce操作后获得的数据或查询结果的集合点。 Compiler(编译器) -它执行HiveQL查询的编译。这会将查询转换为执行计划。该计划包含任务。它还包含MapReduce需要执行的步骤，以获取查询转换的输出。Hive中的编译器将查询转换为抽象语法树（AST）。首先，检查兼容性和编译时错误，然后将AST转换为有向非循环图（DAG）。 Optimizer(优化器) -它对执行计划执行各种转换，以提供优化的有向非循环图DAG。它将转换聚合在一起，例如将连接管道转换为单个连接，以获得更好的性能。优化器还可以拆分任务，例如在reduce操作之前对数据应用转换，以提供更好的性能。 Executor -完成编译和优化后，执行程序将执行任务。执行程序负责管道任务。 CLI，UI和Thrift服务器 - CLI（命令行界面）为外部用户提供与Hive交互的用户界面。Hive中的Thrift服务器允许外部客户端通过网络与Hive交互，类似于JDBC或ODBC协议。 6. Apache Hive教程 - Hive Shellshell是我们与Hive交互的主要方式; 我们可以在Hive shell中的HiveQL中发出命令或查询。Hive Shell几乎与MySQL Shell类似。它是Hive的命令行界面。在Hive Shell中用户可以运行HQL查询。HiveQL也不区分大小写（字符串比较除外）与SQL相同。我们可以在两种模式下运行Hive Shell：非交互模式和交互模式 非交互模式下的 Hive - Hive Shell可以在非交互模式下运行，使用-f选项我们可以指定包含HQL查询的文件的位置。例如: 1hive -f my-script.q 交互模式下的 Hive - Hive Shell也可以在非交互模式下运行。 在这种模式下，我们直接需要转到hive shell并在那里运行查询。在hive shell中，我们可以手动提交所需的查询并获得结果。例如: 1$bin/hive 转到hive shell。 7. Apache Hive的功能Apache Hive有很多功能。让我们一个一个地讨论它们 Hive以更容易的方式提供数据汇总，查询和分析。 Hive支持外部表，这使得可以处理数据而无需实际存储在HDFS中。 Apache Hive完全符合Hadoop的低级接口要求。 它还支持在表级别对数据进行分区以提高性能。 Hive有一个基于规则的优化器，用于优化逻辑计划。 它具有可扩展性，熟悉性和可扩展性。 使用HiveQL不需要任何编程语言知识，基本SQL查询知识就足够了。 我们可以使用Hive在Hadoop中轻松处理结构化数据。 在Hive中查询非常简单，因为它与SQL类似。 我们还可以使用Hive为数据分析运行Ad-hoc查询。 8. Apache Hive的限制Hive具有以下限制 Apache不提供实时查询和行级更新。 Hive还为交互式数据浏览提供可接受的延迟。 这对在线交易处理来说并不好。 Apache Hive查询的延迟通常非常高。 所以，这一切都在Apache Hive教程中。 9.结论在结论中，Hive是一个基于Hadoop构建的数据仓库包，用于数据分析。Hive还使用一种名为HiveQL（HQL）的语言，它自动将类似SQL的查询转换为MapReduce作业。我们还学习了Hive的各种组件，如元存储，优化器等。如果您有任何与此Apache Hive教程相关的查询，请在下面给出的部分中留言。]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive函数]]></title>
    <url>%2F2019%2F02%2F13%2Fhive%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[什么是hive1print(&apos;hello world&apos;);]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装hive]]></title>
    <url>%2F2019%2F02%2F13%2F%E5%AE%89%E8%A3%85hive%2F</url>
    <content type="text"></content>
      <categories>
        <category>hive</category>
      </categories>
  </entry>
</search>
