<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hive-介绍]]></title>
    <url>%2F2019%2F02%2F19%2FHive-%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[本文章翻译来自Data-flair 1.目标 - Apache Hive教程Apache Hive是一个基于Hadoop Haused构建的开源数据仓库系统，用于查询和分析存储在Hadoop文件中的大型数据集。它在Hadoop中处理结构化和半结构化数据。这个Apache Hive教程详细介绍了Apache Hive和Hive历史的基础知识。在这个配置单元教程中，我们将了解蜂巢的需求及其特性。此Hive指南还介绍了Hive体系结构的内部结构，Hive功能和Apache Hive的缺点。那么，让我们开始Apache Hive教程。 2.什么是Hive?Apache Hive是一个基于Hadoop Haused构建的开源数据仓库系统，用于查询和分析存储在Hadoop文件中的大型数据集。最初，您必须编写复杂的 Map-Reduce 作业，但现在在Hive的帮助下，您只需要提交SQL查询。Hive主要针对熟悉SQL的用户。Hive使用称为HiveQL（HQL）的语言，它类似于SQL。HiveQL自动将类似SQL的查询转换为MapReduce作业。Hive抽象了Hadoop的复杂性。需要注意的主要事情是没有必要为Hive学习java。Hive通常在您的工作站上运行，并将您的SQL查询转换为一系列作业，以便在a上执行Hadoop集群。Apache Hive将数据组织到表中。这提供了一种将结构附加到存储在 HDFS中的数据的方法。 3. Hive的历史Facebook数据基础架构团队开发了Hive。Apache Hive也是用于满足Facebook要求的技术之一。它非常受Facebook内部所有用户的欢迎。它被用于在具有数百个用户的群集上运行数千个作业，用于各种应用程序。Facebook上的Apache Hive-Hadoop集群存储了超过2PB的原始数据。它每天定期加载15 TB的数据。现在它被亚马逊，IBM，雅虎，Netflix，金融业监管局（FINRA）等许多公司使用和开发。 4.为什么选择Hive?让我们现在讨论Hive的需求 -Facebook在实施Apache Hive之前遇到了很多挑战。生成的数据大小等挑战增加或爆炸，使得处理它们变得非常困难。传统的RDBMS无法应对压力。因此，Facebook正在寻找更好的选择。为了解决这个问题，Facebook最初尝试使用MapReduce。但它在SQL编程和强制知识方面存在困难，使其成为一种不切实际的解决方案。因此，Apache Hive允许他们克服他们所面临的挑战。使用Apache Hive，他们现在可以执行以下操作： 架构灵活性和演变 表可以分配和分段 Apache Hive表直接在HDFS中定义 JDBC/ODBC驱动程序可用 Apache Hive使开发人员无需编写复杂的Hadoop MapReduce作业即可满足临时需求。因此，hive提供数据的摘要，分析和查询。Hive非常快速且可扩展。它具有很强的可扩展性。由于Apache Hive与SQL类似，因此SQL开发人员很容易学习和实现Hive查询。Hive通过提供用户可以提交SQL查询的界面来降低MapReduce的复杂性。因此，现在业务分析师可以 使用Apache Hive使用大数据并生成见解。它还提供各种数据存储（如 HDFS和HBase）的文件访问。Apache Hive最重要的特性是学习Hive，我们不必学习Java。 5. Hive 结构在介绍Apache Hive之后，现在我们将讨论Hive结构的主要组件。Apache Hive组件是 - Metastore -它存储每个表的元数据，如模式和位置​​。Hive还包括分区元数据。这有助于驱动程序跟踪在群集上分布的各种数据集的进度。它以传统的RDBMS格式存储数据。Hive元数据可帮助驱动程序跟踪数据，这非常重要。备份服务器会定期复制在数据丢失时可以检索的数据。驱动程序 -它就像一个接收HiveQL语句的控制器。驱动程序通过创建会话来启动语句的执行。它监视生命周期和执行进度。驱动程序存储在执行HiveQL语句期间生成的必要元数据。它还充当Reduce操作后获得的数据或查询结果的集合点。编译器 -它执行HiveQL查询的编译。这会将查询转换为执行计划。该计划包含任务。它还包含MapReduce需要执行的步骤，以获取查询转换的输出。Hive中的编译器将查询转换为抽象语法树（AST）。首先，检查兼容性和编译时错误，然后将AST转换为有向 非循环图（DAG）。优化器 -它对执行计划执行各种转换，以提供优化的DAG。它将转换聚合在一起，例如将连接管道转换为单个连接，以获得更好的性能。优化器还可以拆分任务，例如在reduce操作之前对数据应用转换，以提供更好的性能。执行程序 -完成编译和优化后，执行程序将执行任务。执行程序负责管道任务。CLI，UI和Thrift服务器 - CLI（命令行界面）为外部用户提供与Hive交互的用户界面。Hive中的Thrift服务器允许外部客户端通过网络与Hive交互，类似于JDBC或ODBC协议。Apache Hive简介教程培训Apache Hive 6. Apache Hive教程 - Hive Shellshell是我们与Hive交互的主要方式; 我们可以在Hive shell中的HiveQL中发出命令或查询。Hive Shell几乎与MySQL Shell类似。它是Hive的命令行界面。在Hive Shell中，用户可以运行HQL查询。HiveQL也不区分大小写（字符串比较除外）与SQL相同。我们可以在两种模式下运行Hive Shell：非交互模式和交互模式 非交互模式下的 Hive - Hive Shell可以在非交互模式下运行，使用-f选项我们可以指定包含HQL查询的文件的位置。例如-hive -f my-script.q交互模式下的 Hive - Hive Shell也可以在非交互模式下运行。 在这种模式下，我们直接需要转到hive shell并在那里运行查询。在hive shell中，我们可以手动提交所需的查询并获得结果。例如 - $ bin / hive，转到hive shell。 7. Apache Hive的功能Apache Hive有很多功能。让我们一个一个地讨论它们 - Hive以更容易的方式提供数据汇总，查询和分析。Hive支持外部表，这使得可以处理数据而无需实际存储在HDFS中。Apache Hive完全符合Hadoop的低级接口要求。它还支持在表级别对数据进行分区以提高性能。Hive有一个基于规则的优化器，用于优化逻辑计划。它具有可扩展性，熟悉性和可扩展性。使用HiveQL不需要任何编程语言知识，基本SQL查询知识就足够了。我们可以使用Hive在Hadoop中轻松处理结构化数据。在Hive中查询非常简单，因为它与SQL类似。我们还可以使用Hive为数据分析运行Ad-hoc查询。Hadoop测验 8. Apache Hive的限制Hive具有以下限制 - Apache不提供实时查询和行级更新。Hive还为交互式数据浏览提供可接受的延迟。这对在线交易处理来说并不好。Apache Hive查询的延迟通常非常高。所以，这一切都在Apache Hive教程中。希望你喜欢我们的解释。 9.结论在结论中，Hive是一个基于Hadoop构建的数据仓库包，用于数据分析。Hive还使用一种名为HiveQL（HQL）的语言，它自动将类似SQL的查询转换为MapReduce作业。我们还学习了Hive的各种组件，如元存储，优化器等。如果您有任何与此Apache Hive教程相关的查询，请在下面给出的部分中留言。也可以看看- 在Ubuntu上安装Hive在Centos上安装Hive将Hive Metastore配置为MySQL]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive函数]]></title>
    <url>%2F2019%2F02%2F13%2Fhive%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[什么是hive1print(&apos;hello world&apos;);]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装hive]]></title>
    <url>%2F2019%2F02%2F13%2F%E5%AE%89%E8%A3%85hive%2F</url>
    <content type="text"></content>
      <categories>
        <category>hive</category>
      </categories>
  </entry>
</search>
